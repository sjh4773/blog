---
title: "One-way ANOVA"
date: 2021-10-07T15:11:16+09:00
categories:
 - 통계 공부
tags:
 - 통계 공부
---

유튜브 Sapientia a Dei 채널에서 공부한 내용을 정리하였습니다.

- One-way ANOVA
  - 비교할 집단이 세 개 이상인 경우
    - t-test를 세 번하면 될 것 같았으나 할 수 없음
      - 1종오류에 빠짐
    - 따라서, 우리는 새로운 방법을 배워야 함
  - 그 새로운 통계 방법이 바로 One-way ANOVA임
    - One-way는 독립변수가 하나라는 뜻
    - ANOVA는 Analysis of Variance의 약자
    - 한국말로는 분산분석이라고 함

- 변수
  - 독립변수
    - 독립인 변수 - 무엇으로부터 독립일까요?
    - 책이나 인터넷을 찾아보면 이렇게 설명이 되어 있습니다
      - 독립변수 -> 연구자/조사자가 의도적으로 변화시키는 변수
      - 다른 말로 예측변수 혹은 설명변수
    - 여기서 독립은 논리적 관계에서의 독립을 의미합니다
      - 주로 인과관계를 많이 연구/조사하므로 이때 이 인과관계에서 독립적인 위치는 결과보다는 원인일 것입니다
      - 그래서 인과관계에서 원인이 되는 변수가 독립변수가 됩니다
    - 오해하면 안되는 것은 독립변수가 연구자/조사자가 의도적으로 변화시킬 수 있다고 하여 마음대로 해도 된다는 의미는 아닙니다.
  - 종속변수
    - 종속인 변수 - 어디에 종속될까요?
    - 책이나 인터넷을 찾아보면 이렇게 설명이 되어 있습니다
      - 종속변수 -> 연구자/조사자가 독립변수의 변화에 따라 어떻게 변하는지 알고 싶은 변수
      - 다른 말로 반응변수 혹은 결과변수
    - 여기서 종속은 논리적 관계에서의 종속을 의미합니다
      - 주로 인과관계를 많이 연구/조사하므로 이때 이 인과관계에서 종속적인 위치는 원인보다는 결과일 것입니다
      - 그래서 인과관계에서 결과가 되는 변수가 종속변수가 됩니다
  - 통제변수
    - 기본적으로는 독립변수와 동일하나
    - 연구/조사의 주된 관심사가 되는 변수가 아닌 경우
    - 통제변수를 사용하는 이유
      - 고객만족 up -> 재방문율 up
      - 이때,고객만족이 독립변수, 재방문율이 종속변수
      - 그런데, 재방문율에 영향을 미치는 변수가 오직 고객만족 한 개 일리는 없음
      - 따라서, 재방문율에 영향을 미칠 만한 다른 중요한 변수를 같이 감안해야 함
      - 다른 중요한 변수를 감안하고서도 고객만족이 중요한 역할을 한다면, 고객만족은 정말 중요한 변수임
        - 통제변수를 한 개도 감안하지 않는 경우: Model Misspecification 발생

- One-way ANOVA에 사용되는 변수
  - 종속변수: 연속형(Continuous)변수만 가능
  - 독립변수: 이산형/범주형(Discrete/Categorical) 변수만 가능
- 예시
  - 아주 오래전 이야기지만, 과거에는 영상물이 어린이들의 폭력성에
  - 미치는 영향을 연구하기 위해 동일 연령대의 아이들을 세 그룹으로 나누어
  - 한 그룹에는 폭력적인 영화장면을, 다른 그룹에는 드라마를, 마지막 그룹에는 공익광고를 보여줬다.
  - 같은 시간 동안 서로 다른 세 가지의 영상을 본 아이들을 관찰실에 들여보낸 뒤에 아이들이
  - 관찰실에서 보이는 폭력적인 행동을 점수화 하였다

- 독립변수와 종속변수 in ANOVA
  - 종속변수: 아이들의 폭력행동 점수
  - 독립변수: 영상의 종류 (3가지)
    - 폭력영화/드라마/공익광고

- 예시
  - 신종플루 신약을 개발한 어느 제약회사에서 신종플루 감염자를 대상으로 신약의 효과를 측정하고자 한다
    - 종속변수: 신약을 먹은 후 완치 될 때까지 걸린 날짜
    - 독립변수 (3 레벨-3가지 그룹)
      - 새로 개발된 신약
      - 기존의 독감 약
      - 플라시보

- 예시
  - 어느 인터넷 ISP 기업이 고객의 총 지불금액이 고객들의 지불 방법에 따라 차이가 있는지 알고 싶어한다
    - 종속변수 : 고객의 총 지불금액 (Total Charges)
    - 독립변수(4 레벨-4가지 그룹)
      - 은행계좌 자동이체
      - 신용카드
      - 전자수표
      - 종이수표

- One-way ANOVA
  - 하나씩 봅시다
    - Y(ij) = μ + τ(j) + e(ij)
    - 이 공식에서 평균을 좌변으로 넘기면
      - Y(ij) - μ = τ(j) + e(ij)
        - 궁극적으로 위의 식이 의미하는 것은 그룹별(독립변수) 차이가 종속변수에 나타나는 것인지 아닌지를 보겠다는 것이다.
      - Y(ij)는 종속변수를 의미합니다
        - 통계학에서 '=' 좌측은 종속변수입니다
        - 앞 강의를 기억하시나요? ANOVA에서는 종속변수는 연속형변수이어야 합니다
        - 여기서 연속형 종속변수의 값이 대문자 Y에 해당합니다
        - 이렇게 표현하는 이유는 데이터 전체를 한 문자로 대표하여 표기하기 위함입니다
        - 마치 중학교 때 배운 미지수 x와 같은 것입니다
        - 아래첨자(subscript) i와 j는 무엇일까요?
        - 여기서 j는 독립변수의 그룹을 대표하는 문자입니다
        - 그리고 i는 그 그룹 내의 ID입니다
    - 우변의 μ는 평균입니다. 여기에 평균이 왜 있을까요?
      - 종속변수의 값이 100% 독립변수의 영향이라고 볼 수 없기 때문입니다
      - 예를 들어 사과의 출하량을 종속변수로, 비료를 준 그룹과 비료를 주지 않은
      - 그룹의 사과 출하량을 비교할 때, 비료를 주지 않은 그룹의 사과 출하량이 상식적으로 "0"이 되지는 않겠지요
      - 어떠한 변화를 주지 않아도 나오는 값을 μ로 설정
      - 하지만 ANOVA에서 이 평균값은 우리의 관심사가 아닙니다.
      - 관심사는 τ(j)입니다
        - 독립변수 τ(j)(타우_제이)라고 읽습니다
        - 여기에서 τ는 독립변수를 의미합니다
        - 또한 j는 그룹을 의미합니다(j = 1, 2, 3, 4 ...)
    - 그럼 마지막에 있는 e(ij)는 뭘까요?
       - 마찬가지로 j는 독립변수의 그룹을 대표하는 문자입니다
       - 그리고 i는 그 그룹 내의 ID 입니다
       - 여기서 e가 의미 하는 것은 오차(error)입니다
   - 여기에서 말하는 오차는 그룹간의 차이인 τ(j)에 의해 설명되지 않는 오차
     - 즉, random한 오차입니다
     - 이 오차는 무작위로 발생했으므로 큰 의미는 없다고 가정합니다 
     - 물론, 만약 이 오차가 무작위로 발생하지 않았다고 하면 뭔가 문제가 있는 것이죠

- z-test에는 z-value (z값)이 있었고
- t-test에는 t-value (t값)이 있었습니다
- ANOVA에는 뭐가 있을까요?
  - 바로 F-value(F값)입니다
  - 물론 이와 함께 F분포도 있습니다
  - 앞의 다른 테스트와 마찬가지로 F-값을 구해서 F분포를 확인합니다
- 처음 ANOVA를 시작할 때 질문이 기억나나요?
  - 우리가 궁금한 것은 세 개 이상의 그룹의 평규니 같은지 다른지 입니다
  - 그런데 왜 ANOVA는 평균분석이 아니라 분산분석이란 이름을 가지고 있을까요?

- F-value - F값이란?
  - 이것만 기억하자!!
    - F값이란 두개의 분산의 비율이다 -> 두 개의 평균이 필요하다
    - 그래서 우리는 이것을 분산분석이라 부른다
    - 그런데 여전히 이상합니다
       - 두개의 분산으로 평균값이 같은지 다른지를 어떻게 알 수 있을까요?
    - 첫 번째 분산 : GM(전체평균)으로부터 각 그룹의 평균사이 분산
    - 이 첫번째 분산인 Between Variance가 크다는 것은?
      - 전체 평균으로부터 각 그룹의 평균값이 멀리 떨어져 있다 -> 따라서, 적어도 어떤 그룹 한 개는 다른 그룹과 평균이 다를 수 있다
    - 문제는 이 Between Variance가 얼마나 커야 통계적으로 큰 걸까요?
    - 즉, 이 Between Variance가 우연히 클 가능성은 확률적으로 얼마나 될까요?
    - 이제 t-test에서 보았듯이 조금 방법이 보이지요?
      - 우리는 Between Variance와 비교할 다른 Variace가 필요하겠죠?
    - 두 번째 분산 : 그룹내의 분산
    - 이 두번째 부산인 Within Variance의 의미는?
      - t-test의 t-value(t-값) 계산시의 분모의 표준편차와 같은 의미 -> random한 (즉, 무의미한) 변화의 정도이므로
    - Between Variance가 Within Variance보다 충분히커야 우리는 Between Variance가 통계적으로 크다고 말할 수 있고,
    - 이것은 적어도 어느 한 그룹의 평균값이 전체 평균과는 다르다고 할 수 있다
    - 따라서, F-value(F값이란)
    - F-value = (Between Variance / Within Variance)
    - 결론적으로, t-값과 마찬가지로 우리의 관심인 분자부분의 분산을 비교대상인 분모부분의 분산과 비교하여 비율로써 나타낸 값이 F값
    - 분모의 within variance는 random한 변동값으로, between variance가 이보다는 훨씬 커야 한다는 것을 의미함
 
- F-value는 분산의 비율이다 그 두 개의 분산은 Between Variance와 Within Variance이다.
- 분자에 있는 Beetween Variance가 우리의 관심사이다 왜냐하면 세 개 이상의 그룹의 평균값을 비교하고자 할 때
- 평균값 자체를 비교하는 것이 아니라 Between Variance 즉 전체 평균으로 부터 각각의 그룹의 평균이 얼마만큼 떨어져있는가라는게 Between Variance다
- 이 값이 크면 클수록 적어도 누군가 한 그룹은 분명히 다른 그룹과 다를 것이다. 문제는 이 Between Variance가 얼마나 커야 큰 것인지 알 수 없기 때문에
- 비교 대상이 필요했고 그 비교 대상이 Within Variance 이다. Within Variance는 집단 내의 그룹내의 분산이다.
- 결론적으로 아래쪽의 분모의 값은 비교의 대상이며 랜덤한 변화량으로 인식된다.

- 통계적 가설
  - 귀무가설 : 모든 그룹의 평균은 같다.
  - 대립가설 : 적어도 한 그룹의 평균은 다르다
- 왜 그럴까요?
  - 만약, F값이 충분히 커서 유의 하다면 (p-value < 0.05), 이는 우리의 Between Variance가 충분히 크다는 의미인데,
  - 이것만으로는 몇 개의 그룹이 그리고 어떤 그룹이 전체평균과 어떻게 다르다는 것인지 알 수 없음
- 그런데 유의하다는 것은 정확히 무엇일까?
- 다시 통계적 가설로 돌아가 보자
  - 귀무가설 : 모든 그룹의 평균은 같다.
  - 대립가설 : 적어도 한 그룹의 평균은 다르다
- 그렇다면, 우리가 현재 아는 것은 다닞, 적어도 셋 중 한 그룹의 평균이 다르다는 것 뿐이다
- 뭐가 어떻게 다르다는 것일까?
- 단순히 One-way ANOVA의 결과만으로는 어떤 그룹이 어떻게 다른지 알 수 없음
- 그러므로, ANOVA에서는 유의하다는 결과가 나오면 자동으로 사후검정을 해야함
  - 사후검정이란?
    - 일종의 여러 다발의 t-test
    - 그러나 Type-1 error를 발생시키지 않음
    - 각 그룹의 평균이 다른 그룹의 평균과 같은지 다른지 개별 비교 가능
    - 사후검정의 종류
       - Fisher's LSD / Bonferroni / Sheffe / Turkey / Dunca
       - 대부분의 경우 무엇을 써도 큰 차이는 없음
